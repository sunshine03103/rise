# 1.简介

消息保存跟据topic进行分类，消息发送者成为producer，消息接受者成为consumer。producer和consumer都依赖于zookeeper来保证系统可用性。

一个topic可以认为是一类消息，每个topic将被分成多个partition分区。每个partition在存储层层面是append log文件追加。消息会被追加到log文件的尾部。
每条消息在文件中的位置称为offset(偏移量)，offset为一个long型数字，它唯一地标记一条消息。

日志文件将会跟据broker中的配置要求，留一定的时间之后删除。

consumer需要保存消费信息的offset。消费时offset将会线性的向前驱动。

consumer和producer状态信息有zookeeper保存。

kakka基于文件存储。通过分区，可以将日志内容分散到多个server上来避免文件尺寸达到单机磁盘的上限。
越多partition可以容纳更多的consumer，提高并发消费能力。

每人partition都有一个server为leader.leader负责所有的读写操作，如果leader失效，那么将会有其他的follwer来接管，成为新的leader.

producers将消息发到指定topic，同时producer也能决定将此消息归属哪个partition.

对于一个topic，同一个group中不能有多于partitions个数的consumer同时消费，否则意味着某此consumer将无法得到消息。

使用场景：1.消息系统。2.网站活性跟踪。3.日志收集

# ２.设计原理

持久性：kafka使用的是文件存储消息。为了减少磁盘写入次数。broker会将消息暂时buffer起来，当消息的个数（或尺寸）达到一定阀值时，再flush到磁盘，这样减少磁盘IO调用次数。

性能：
1.producer端和consumer端批量fetch多条消息。
2.sendfile系统提升网络IO:将文件数据映射到系统内存中，socket直接读取相应的内存区域即可。
3.kafka支持gzip/snappy等多种压缩方式来传输网络IO.

生产者：
1.负载均衡:
producer将会和topic下所有partition leader保持socket连接。消息有producer直接通过socket发送到broker中间不会经过任何“路由层”。
product客户端决定消息被路由到哪个partition上。
partition leader的位置注册在zookeeper中，producer作为zookeeper client已经注册了watch用来监听parition leader的变更事件。

2.异步发送:批量延迟发送事实上提升了网络效率，但当producer失效时，尚未发送的消息将会丢失。

消费者:kafka采用了pull方式，在consumer在和broker建立连接后，主动去pull消息。
1.consumer可以根据自己的消费能力适时去fetch消息并处理。
2.可以控制消息消费的进度（offset）和消费数量。
3.consumer可以在本地保存最后消息的offset并间歇性地向zookeeper注册offset.

消息传送机制
1.at most once 发送一次无论成败都不会重发。
2.at least once 消息至少发送一次，直到接收成功（首选，重复接收的可能，不会丢失数据）
3.exactly once 消息只会发送一次

复制备份
备份个数可以通过broker配置文件来设定。
leader处理所有的读写请求，follower需要和leader保持同步。
消息被committed此时consumer才能消费它，只有一个replicas实例存活，可以保证消息的正常发送与接收。只要zookeeper集群存活即可（不同于其他分布式存储，比如hbase需要多数派存活才行）。
当leader失效时从follwer中选择一个leader,如果一个server上有过多partition leader意味着server承受更多的IO压力。要考虑到负载均衡。

日志
log file组成的命名为“最小offset.kafka”

分配
kafka使用zookeeper来存储一些meta信息，使用了zookeeper watch机制来发现meta信息的变更并作出相应的动作（consumer失效，触发负载均衡等）;


# 3.配置及实践


